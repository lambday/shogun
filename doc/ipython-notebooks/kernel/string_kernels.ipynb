{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "String Kernels in Shogun"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "By Soeren Sonnenburg ([sonney2k](https://github.com/sonney2k)), Soumyajit De ([lambday](https://github.com/lambday))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook introduces a large variety of string kernels that are part of Shogun. These are extremely useful for <i>classifying</i> or <i>clustering</i> sequence data, specially in the context of <i>text classification</i> (such as detecting SPAM mails), <i>security</i> (detecting viruses and malware) and <i>bioinformatics</i> (<i>e.g.</i> genomic sequence detection problem)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[String Kernels](#String-Kernels)\n",
      "<ul>\n",
      "    <li>[Spectrum kernels](#Spectrum-Kernel)\n",
      "    <ul>\n",
      "        <li>CommUlongStringKernel</li>\n",
      "        <li>CommWordStringKernel</li>\n",
      "        <li>FixedDegree String kernel</li>\n",
      "        <li>SpectrumRBFKernel</li>\n",
      "        <li>SpectrumMismatchRBFKernel</li>\n",
      "        <li>WeightedCommWordString</li>\n",
      "    </ul>\n",
      "    </li>\n",
      "    <li>[Linear and polynomial string kernels](#Linear-and-Polynomial-String-Kernels)\n",
      "    <ul>\n",
      "        <li>Linear string kernel</li>\n",
      "        <li>[Subsequence kernel](#Subsequence-Kernel)</li>\n",
      "        <li>PolyMatchStringKernel</li>\n",
      "        <li>PolyMatchWordStringKernel</li>\n",
      "        <li>MatchWordStringKernel</li>\n",
      "        <li>Distant segments kernel</li>\n",
      "        <li>Locality improved kernel</li>\n",
      "        <li>SimpleLocalityImprovedStringKernel</li>\n",
      "        <li>SNPStringKernel</li>\n",
      "    </ul>\n",
      "    </li>\n",
      "    <li>Weighted degree kernels\n",
      "    <ul>\n",
      "        <li>Oligo</li>\n",
      "        <li>Regulaty Modules kernel</li>\n",
      "        <li>WeightedDegreePositionStringKernel</li>\n",
      "        <li>WeightedDegreeRBFKernel</li>\n",
      "        <li>WeightedDegreeStringKernel</li>\n",
      "    </ul>\n",
      "    </li>\n",
      "    <li>Fisher and TOP kernels\n",
      "    <ul>\n",
      "        <li>HistogramWordStringKernel</li>\n",
      "    </ul>\n",
      "    </li>\n",
      "    <li>Others\n",
      "    <ul>\n",
      "        <li>SalzbergWordString kernel</li>\n",
      "        <li>Sparse Spatial Sample String Kernel</li>\n",
      "    </ul>\n",
      "    </li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "String Kernels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have seen the use of <i>Kernels</i> in quite a few places already, <i>e.g.</i> in the [Binary Classification with Support Vector Machines](http://shogun-toolbox.org/static/notebook/current/SupportVectorMachines.html) notebook, where a <i>[Gaussian kernel](http://en.wikipedia.org/wiki/Radial_basis_function_kernel)</i> is used in the [Support Vector Machine](http://en.wikipedia.org/wiki/Support_vector_machine)</a> (SVM) framework to classify data points in a 2-dimensional space. These kernels intuitively represent a measure of <i>\"similarity\"</i> between two input entities. For entites defined in <i>[Euclidean space](http://en.wikipedia.org/wiki/Euclidean_space)</i> (represented as $d$-dimensional vectors, $\\mathbf{x},\\mathbf{x'}\\in\\mathbb{R}^{d}$, for some $d$), their distance ($||\\mathbf{x}-\\mathbf{x'}||$) or even <i>dot-product</i> ($\\mathbf{x}\\cdot\\mathbf{x'}$) can be used in a <i>kernel function</i>, $k$, formally defined as \n",
      "\n",
      "$$k(\\mathbf{x},\\mathbf{x'}):\\mathbb{R}^{d}\\times\\mathbb{R}^{d}\\rightarrow \\mathbb{R}.$$\n",
      "\n",
      "But things get pretty unintuitive when we deal with some <i>structured</i> input space instead, such as strings, trees or graphs. Measuring similarities between two strings $\\mathbf{s}$ and $\\mathbf{s'}$ is often more challenging task than just counting maching characters due to the diversity of the scenarios that those strings might represent - for example, a human readable text in English or French with punctuation characters in a text classification problem or a DNA, RNA or Protein sequence in a genomic sequence detection problem - just to name a few. Therefore, designing string kernels is very context specific and they differ vastly in their <i>feature maps</i> (function $\\boldsymbol\\Phi(\\mathbf{s})$ that maps $\\mathbf{s}\\in\\Sigma^{*}$, $\\Sigma$ being the <i>alphabet</i>, into a <i>[Hilbert space](http://en.wikipedia.org/wiki/Hilbert_space)</i> to be used in the kernel in an <i>inner product</i>, <i>i.e.</i> $k(\\mathbf{s},\\mathbf{s'})=\\langle\\boldsymbol\\Phi(\\mathbf{s}),\\boldsymbol\\Phi(\\mathbf{s'})\\rangle$) and as a result, computation procedures.\n",
      "\n",
      "A number of string kernels came into existence to address the task, with a few better than others in some specific problems. In general, they can be broadly categorized into two types - first, the ones that are directly defined on strings, and second, kernels that are defined on [generative models](http://en.wikipedia.org/wiki/Generative_model) (like [hidden Markov models](http://en.wikipedia.org/wiki/Hidden_Markov_model), e.g. [Jaakkola et al., 2000](http://compbio.soe.ucsc.edu/discriminative/Jaakola2-1998.ps), Tsuda et al., [2002b](http://machinelearning.wustl.edu/mlpapers/paper_files/nips02-AA56.pdf), [2000c](http://www.cs.berkeley.edu/~jordan/courses/281B-spring04/readings/tsuda.pdf)), or by using appropriately defined scores (for instance alignment scores; e.g. [Liao and Noble, 2002](http://noble.gs.washington.edu/papers/fps-svm.pdf), [Vert et al., 2004](http://cbio.ensmp.fr/~jvert/publi/04kmcbbook/saigo.pdf)), which directly works on strings but learnt or, respectively, defined independently beforehand.\n",
      "\n",
      "In this notebook, we will investigate about different types of string kernels present in Shogun categorically with demonstration of their usage.\n",
      "\n",
      "[[Back to contents](#Contents)]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Spectrum Kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Linear and Polynomial String Kernels"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Subsequence Kernel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In [Lodhi et al., 2002](http://machinelearning.wustl.edu/mlpapers/paper_files/LodhiSSCW02.pdf), a different types of kernel is introduced."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import SubsequenceStringKernel\n",
      "from modshogun import StringCharFeatures, ALPHANUM\n",
      "import numpy as np\n",
      "\n",
      "train_data = ['CAT', 'DOOM', 'CAR', 'BOOM']\n",
      "test_data = ['BAT', 'SOON']\n",
      "\n",
      "train_labels = np.array([1, -1, 1, -1])\n",
      "test_labels = np.array([1, -1])\n",
      "\n",
      "maxlen = 1\n",
      "decay = 1\n",
      "\n",
      "feats_train = StringCharFeatures(train_data, ALPHANUM)\n",
      "feats_test = StringCharFeatures(test_data, ALPHANUM)\n",
      "\n",
      "kernel = SubsequenceStringKernel(10, maxlen, decay)\n",
      "\n",
      "kernel.init(feats_train, feats_train)\n",
      "km_train = kernel.get_kernel_matrix()\n",
      "print 'train kernel matrix:\\n', km_train\n",
      "kernel.init(feats_train, feats_test)\n",
      "km_test = kernel.get_kernel_matrix()\n",
      "print 'test kernel matrix:\\n', km_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import LibSVM, BinaryLabels\n",
      "\n",
      "maxlen = 4\n",
      "decay = 0.9\n",
      "kernel = SubsequenceStringKernel(feats_train, feats_train, maxlen, decay)\n",
      "C = 1.0\n",
      "labels = BinaryLabels(train_labels)\n",
      "svm = LibSVM(C, kernel, labels)\n",
      "svm.train()\n",
      "\n",
      "kernel.init(feats_train, feats_test)\n",
      "print 'predicted labels:', svm.apply(feats_test).get_labels()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Second section"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second section is the place to get into more sophisticated parts, for instance details of the method you are presenting and even illustrating its performance in real data sets."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is nice idea to include links to Shogun's Doxygen documentation. For example, this a link to the [SGObject class](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CSGObject.html) and this other one to the [`get_name`](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CSGObject.html#a471caa9005cc581cb4514c0705b698ee) of this class."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do not forget to write a reference list! Books, scientific articles or resources in the web. In case of articles, include a link to the paper if this is publicly available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- S\u00f6ren Sonnenburg, [Machine Learning for Genomic Sequence Analysis - Dissertation](http://sonnenburgs.de/soeren/publications/Son08.pdf\u200e)\n",
      "- More authors. Reference 2.\n",
      "- [iPython notebook documentation](http://ipython.org/ipython-doc/dev/interactive/notebook.html).\n",
      "- ..."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}